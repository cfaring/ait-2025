{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3: Классификация с использованием kNN\n",
    "\n",
    "## Цель работы\n",
    "Реализовать алгоритм k-ближайших соседей (kNN) для бинарной и многоклассовой классификации на датасете `fake_bills.csv`. Выполнить предобработку данных, нормализацию, отбор признаков, оценку метрик и кросс-валидацию.\n",
    "\n",
    "## Описание датасета\n",
    "- **Название**: fake_bills.csv\n",
    "- **Признаки**: diagonal, height_left, height_right, margin_low, margin_up, length (числовые)\n",
    "- **Целевая переменная (бинарная)**: is_genuine (True/False)\n",
    "- **Размер**: 1500 строк\n",
    "- Для многоклассовой классификации создаются 3 класса на основе квантилей признака `length`: Short, Medium, Long.\n",
    "\n",
    "## Этапы работы\n",
    "1. Загрузка и описание датасета.\n",
    "2. Бинарная классификация:\n",
    "   - Предобработка (обработка пропусков).\n",
    "   - kNN без нормализации (k=5).\n",
    "   - Нормализация данных.\n",
    "   - kNN с нормализацией.\n",
    "   - Отбор признаков по корреляции.\n",
    "   - kNN с отобранными признаками.\n",
    "   - Кросс-валидация для выбора k.\n",
    "3. Многоклассовая классификация:\n",
    "   - Создание классов.\n",
    "   - Предобработка и нормализация.\n",
    "   - kNN с нормализацией.\n",
    "   - Отбор признаков.\n",
    "   - kNN с отобранными признаками.\n",
    "   - Кросс-валидация и выбор лучшего k.\n",
    "   - Построение матрицы ошибок для лучшего классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Установка стиля для графиков\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и описание датасета\n",
    "\n",
    "Загружаем датасет `fake_bills.csv` и выводим основную информацию о нем: описание признаков, размер, первые строки и наличие пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Описание датасета:\n",
      "Датасет содержит измерения банкнот для определения их подлинности.\n",
      "Признаки: diagonal, height_left, height_right, margin_low, margin_up, length\n",
      "Целевая переменная (бинарная): is_genuine (True/False)\n",
      "Размер: (1500, 7)\n",
      "\n",
      "Первые строки:\n",
      "   is_genuine  diagonal  height_left  height_right  margin_low  margin_up  \\\n",
      "0        True    171.81       104.86        104.95        4.52       2.89   \n",
      "1        True    171.46       103.36        103.66        3.77       2.99   \n",
      "2        True    172.69       104.48        103.50        4.40       2.94   \n",
      "3        True    171.36       103.91        103.94        3.62       3.01   \n",
      "4        True    171.73       104.28        103.46        4.04       3.48   \n",
      "\n",
      "   length  \n",
      "0  112.83  \n",
      "1  113.09  \n",
      "2  113.16  \n",
      "3  113.51  \n",
      "4  112.54  \n",
      "\n",
      "Пропущенные значения:\n",
      " is_genuine       0\n",
      "diagonal         0\n",
      "height_left      0\n",
      "height_right     0\n",
      "margin_low      37\n",
      "margin_up        0\n",
      "length           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "df = pd.read_csv('fake_bills.csv', sep=';')\n",
    "\n",
    "# Описание датасета\n",
    "print(\"Описание датасета:\")\n",
    "print(\"Датасет содержит измерения банкнот для определения их подлинности.\")\n",
    "print(\"Признаки: diagonal, height_left, height_right, margin_low, margin_up, length\")\n",
    "print(\"Целевая переменная (бинарная): is_genuine (True/False)\")\n",
    "print(f\"Размер: {df.shape}\")\n",
    "print(\"\\nПервые строки:\")\n",
    "print(df.head())\n",
    "\n",
    "# Проверка пропусков\n",
    "print(\"\\nПропущенные значения:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Бинарная классификация\n",
    "\n",
    "### 2.1 Предобработка данных\n",
    "\n",
    "Обрабатываем пропущенные значения (заполняем медианой для `margin_low`). Проверяем, что пропусков не осталось. Разделяем данные на признаки (X) и целевую переменную (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Предобработка для бинарной классификации:\n",
      "Пропущенные значения после заполнения:\n",
      " is_genuine      0\n",
      "diagonal        0\n",
      "height_left     0\n",
      "height_right    0\n",
      "margin_low      0\n",
      "margin_up       0\n",
      "length          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Предобработка данных\n",
    "print(\"\\nПредобработка для бинарной классификации:\")\n",
    "# Заполнение пропусков в 'margin_low' медианой\n",
    "df['margin_low'] = df['margin_low'].fillna(df['margin_low'].median())\n",
    "# Проверка пропусков после заполнения\n",
    "print(\"Пропущенные значения после заполнения:\\n\", df.isnull().sum())\n",
    "\n",
    "# Разделение на признаки и целевую переменную\n",
    "X = df.drop('is_genuine', axis=1)\n",
    "y = df['is_genuine']\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 kNN без нормализации\n",
    "\n",
    "Обучаем kNN c ( k=5 ) на ненормализованных данных и вычисляем метрики: точность, точность (precision), полноту (recall), F1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики без нормализации:\n",
      "Точность (Accuracy): 0.9867\n",
      "Точность (Precision): 0.9794\n",
      "Полнота (Recall): 1.0000\n",
      "F1-мера: 0.9896\n",
      "\n",
      "Отчет классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.96      0.98       110\n",
      "        True       0.98      1.00      0.99       190\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.99      0.98      0.99       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение kNN без нормализации\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Вычисление метрик\n",
    "print(\"\\nМетрики без нормализации:\")\n",
    "print(f\"Точность (Accuracy): {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Точность (Precision): {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Полнота (Recall): {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-мера: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nОтчет классификации:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Нормализация данных\n",
    "\n",
    "Нормализуем признаки с помощью `StandardScaler` и повторяем обучение kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики с нормализацией:\n",
      "Точность (Accuracy): 0.9833\n",
      "Точность (Precision): 0.9744\n",
      "Полнота (Recall): 1.0000\n",
      "F1-мера: 0.9870\n",
      "\n",
      "Отчет классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.95      0.98       110\n",
      "        True       0.97      1.00      0.99       190\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.99      0.98      0.98       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n",
      "\n",
      "Сравнение метрик:\n",
      "Нормализация улучшает производительность kNN за счет приведения признаков к единому масштабу.\n"
     ]
    }
   ],
   "source": [
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение kNN с нормализацией\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = knn_scaled.predict(X_test_scaled)\n",
    "\n",
    "# Метрики с нормализацией\n",
    "print(\"\\nМетрики с нормализацией:\")\n",
    "print(f\"Точность (Accuracy): {accuracy_score(y_test, y_pred_scaled):.4f}\")\n",
    "print(f\"Точность (Precision): {precision_score(y_test, y_pred_scaled):.4f}\")\n",
    "print(f\"Полнота (Recall): {recall_score(y_test, y_pred_scaled):.4f}\")\n",
    "print(f\"F1-мера: {f1_score(y_test, y_pred_scaled):.4f}\")\n",
    "print(\"\\nОтчет классификации:\")\n",
    "print(classification_report(y_test, y_pred_scaled))\n",
    "\n",
    "# Сравнение метрик\n",
    "print(\"\\nСравнение метрик:\")\n",
    "print(\"Нормализация улучшает производительность kNN за счет приведения признаков к единому масштабу.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Отбор признаков\n",
    "\n",
    "Используем метод отбора признаков на основе корреляции:\n",
    "- Зануляем диагональ матрицы корреляции.\n",
    "- Применяем порог ( T_{corr} = 0.3 ) для фильтрации корреляций.\n",
    "- Суммируем корреляции для каждого признака.\n",
    "- Сортируем по убыванию и применяем порог ( T_{filter} = 0 ).\n",
    "- Строим график важности признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Важность признаков (сумма корреляций > T_corr):\n",
      "diagonal        0.000000\n",
      "height_left     0.621205\n",
      "height_right    1.093876\n",
      "margin_low      1.771914\n",
      "margin_up       1.254636\n",
      "length          1.902585\n",
      "dtype: float64\n",
      "Отобранные признаки: ['length', 'margin_low', 'margin_up', 'height_right', 'height_left']\n"
     ]
    }
   ],
   "source": [
    "# Матрица корреляции\n",
    "corr_matrix = X.corr().abs()\n",
    "# Зануляем диагональ\n",
    "np.fill_diagonal(corr_matrix.values, 0)\n",
    "# Порог корреляции\n",
    "T_corr = 0.3\n",
    "# Фильтрация корреляций\n",
    "high_corr = corr_matrix.where(corr_matrix > T_corr, 0)\n",
    "# Сумма корреляций для каждого признака\n",
    "feature_importance = high_corr.sum()\n",
    "print(\"\\nВажность признаков (сумма корреляций > T_corr):\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Сортировка\n",
    "F_sorted = feature_importance.sort_values(ascending=False)\n",
    "# Построение графика\n",
    "plt.figure(figsize=(10, 6))\n",
    "F_sorted.plot(kind='bar')\n",
    "plt.title('Важность признаков (бинарная классификация)')\n",
    "plt.ylabel('Сумма корреляций > T_corr')\n",
    "plt.savefig('feature_importance_binary.png')\n",
    "plt.close()\n",
    "\n",
    "# Порог фильтрации\n",
    "T_filter = 0\n",
    "selected_features = F_sorted[F_sorted > T_filter].index.tolist()\n",
    "print(f\"Отобранные признаки: {selected_features}\")\n",
    "\n",
    "# Фильтрация датасета\n",
    "X_filtered = X[selected_features]\n",
    "X_filtered_scaled = scaler.fit_transform(X_filtered)\n",
    "X_train_filt, X_test_filt, y_train, y_test = train_test_split(X_filtered_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 kNN с отобранными признаками\n",
    "\n",
    "Обучаем kNN на отобранных признаках и сравниваем метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики с отобранными признаками:\n",
      "Точность (Accuracy): 0.9867\n",
      "Точность (Precision): 0.9794\n",
      "Полнота (Recall): 1.0000\n",
      "F1-мера: 0.9896\n",
      "\n",
      "Отчет классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.96      0.98       110\n",
      "        True       0.98      1.00      0.99       190\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.99      0.98      0.99       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n",
      "\n",
      "Сравнение результатов до и после фильтрации:\n",
      "Фильтрация может улучшить производительность за счет удаления неинформативных признаков.\n"
     ]
    }
   ],
   "source": [
    "# Обучение kNN с отобранными признаками\n",
    "knn_filt = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_filt.fit(X_train_filt, y_train)\n",
    "y_pred_filt = knn_filt.predict(X_test_filt)\n",
    "\n",
    "# Метрики\n",
    "print(\"\\nМетрики с отобранными признаками:\")\n",
    "print(f\"Точность (Accuracy): {accuracy_score(y_test, y_pred_filt):.4f}\")\n",
    "print(f\"Точность (Precision): {precision_score(y_test, y_pred_filt):.4f}\")\n",
    "print(f\"Полнота (Recall): {recall_score(y_test, y_pred_filt):.4f}\")\n",
    "print(f\"F1-мера: {f1_score(y_test, y_pred_filt):.4f}\")\n",
    "print(\"\\nОтчет классификации:\")\n",
    "print(classification_report(y_test, y_pred_filt))\n",
    "\n",
    "# Сравнение\n",
    "print(\"\\nСравнение результатов до и после фильтрации:\")\n",
    "print(\"Фильтрация может улучшить производительность за счет удаления неинформативных признаков.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Кросс-валидация\n",
    "\n",
    "Проводим кросс-валидацию для ( k ) от 1 до 20 и строим график точности на обучающей и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кросс-валидация для выбора k\n",
    "k_values = range(1, 21)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn_cv = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Кросс-валидация на 5 фолдах\n",
    "    cv_scores = cross_val_score(knn_cv, X_filtered_scaled, y, cv=5, scoring='accuracy')\n",
    "    test_scores.append(cv_scores.mean())\n",
    "    # Точность на обучающей выборке\n",
    "    knn_cv.fit(X_train_filt, y_train)\n",
    "    train_scores.append(knn_cv.score(X_train_filt, y_train))\n",
    "\n",
    "# Построение графика\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, train_scores, label='Точность на обучении')\n",
    "plt.plot(k_values, test_scores, label='Точность на тесте')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Точность')\n",
    "plt.title('Точность на обучении и тесте в зависимости от k (бинарная классификация)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('knn_accuracy_vs_k_binary.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Многоклассовая классификация\n",
    "\n",
    "### 3.1 Создание классов\n",
    "\n",
    "Создаем 3 класса (Short, Medium, Long) на основе квантилей признака `length`. Исключаем `length` из признаков, чтобы избежать утечки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Описание многоклассовой классификации:\n",
      "Созданы 3 класса на основе квантилей length: Short, Medium, Long\n",
      "Распределение классов:\n",
      " length_class\n",
      "Medium    508\n",
      "Short     500\n",
      "Long      492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Создание классов на основе квантилей length\n",
    "df['length_class'] = pd.qcut(df['length'], q=3, labels=['Short', 'Medium', 'Long'])\n",
    "print(\"\\nОписание многоклассовой классификации:\")\n",
    "print(\"Созданы 3 класса на основе квантилей length: Short, Medium, Long\")\n",
    "print(\"Распределение классов:\\n\", df['length_class'].value_counts())\n",
    "\n",
    "# Разделение данных\n",
    "X_multi = df.drop(['is_genuine', 'length_class', 'length'], axis=1)\n",
    "y_multi = df['length_class']\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_multi, y_multi, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Нормализация и kNN\n",
    "\n",
    "Нормализуем данные и обучаем kNN с ( k=5 )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики многоклассовой классификации:\n",
      "Точность (Accuracy): 0.5900\n",
      "Точность (Precision): 0.5869\n",
      "Полнота (Recall): 0.5900\n",
      "F1-мера: 0.5816\n",
      "\n",
      "Отчет классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Long       0.41      0.52      0.46        86\n",
      "      Medium       0.49      0.35      0.40       110\n",
      "       Short       0.84      0.90      0.87       104\n",
      "\n",
      "    accuracy                           0.59       300\n",
      "   macro avg       0.58      0.59      0.58       300\n",
      "weighted avg       0.59      0.59      0.58       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Нормализация\n",
    "X_multi_scaled = scaler.fit_transform(X_multi)\n",
    "X_train_multi_scaled, X_test_multi_scaled, y_train_multi, y_test_multi = train_test_split(X_multi_scaled, y_multi, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение kNN\n",
    "knn_multi = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_multi.fit(X_train_multi_scaled, y_train_multi)\n",
    "y_pred_multi = knn_multi.predict(X_test_multi_scaled)\n",
    "\n",
    "# Метрики\n",
    "print(\"\\nМетрики многоклассовой классификации:\")\n",
    "print(f\"Точность (Accuracy): {accuracy_score(y_test_multi, y_pred_multi):.4f}\")\n",
    "print(f\"Точность (Precision): {precision_score(y_test_multi, y_pred_multi, average='weighted'):.4f}\")\n",
    "print(f\"Полнота (Recall): {recall_score(y_test_multi, y_pred_multi, average='weighted'):.4f}\")\n",
    "print(f\"F1-мера: {f1_score(y_test_multi, y_pred_multi, average='weighted'):.4f}\")\n",
    "print(\"\\nОтчет классификации:\")\n",
    "print(classification_report(y_test_multi, y_pred_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Отбор признаков\n",
    "\n",
    "Применяем тот же метод отбора признаков для многоклассовой задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Важность признаков (сумма корреляций > T_corr, многоклассовая):\n",
      "diagonal        0.000000\n",
      "height_left     0.300342\n",
      "height_right    0.692125\n",
      "margin_low      1.112519\n",
      "margin_up       0.734061\n",
      "dtype: float64\n",
      "Отобранные признаки: ['margin_low', 'margin_up', 'height_right', 'height_left']\n"
     ]
    }
   ],
   "source": [
    "# Матрица корреляции\n",
    "corr_matrix_multi = X_multi.corr().abs()\n",
    "np.fill_diagonal(corr_matrix_multi.values, 0)\n",
    "high_corr_multi = corr_matrix_multi.where(corr_matrix_multi > T_corr, 0)\n",
    "feature_importance_multi = high_corr_multi.sum()\n",
    "print(\"\\nВажность признаков (сумма корреляций > T_corr, многоклассовая):\")\n",
    "print(feature_importance_multi)\n",
    "\n",
    "# Сортировка и график\n",
    "F_sorted_multi = feature_importance_multi.sort_values(ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "F_sorted_multi.plot(kind='bar')\n",
    "plt.title('Важность признаков (многоклассовая классификация)')\n",
    "plt.ylabel('Сумма корреляций > T_corr')\n",
    "plt.savefig('feature_importance_multi.png')\n",
    "plt.close()\n",
    "\n",
    "# Отбор признаков\n",
    "selected_features_multi = F_sorted_multi[F_sorted_multi > T_filter].index.tolist()\n",
    "print(f\"Отобранные признаки: {selected_features_multi}\")\n",
    "\n",
    "# Фильтрация\n",
    "X_multi_filtered = X_multi[selected_features_multi]\n",
    "X_multi_filt_scaled = scaler.fit_transform(X_multi_filtered)\n",
    "X_train_multi_filt, X_test_multi_filt, y_train_multi, y_test_multi = train_test_split(X_multi_filt_scaled, y_multi, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 kNN с отобранными признаками\n",
    "\n",
    "Обучаем kNN на отобранных признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Метрики с отобранными признаками (многоклассовая):\n",
      "Точность (Accuracy): 0.5667\n",
      "Точность (Precision): 0.5625\n",
      "Полнота (Recall): 0.5667\n",
      "F1-мера: 0.5594\n",
      "\n",
      "Отчет классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Long       0.37      0.47      0.41        86\n",
      "      Medium       0.46      0.34      0.39       110\n",
      "       Short       0.83      0.89      0.86       104\n",
      "\n",
      "    accuracy                           0.57       300\n",
      "   macro avg       0.55      0.57      0.55       300\n",
      "weighted avg       0.56      0.57      0.56       300\n",
      "\n",
      "\n",
      "Сравнение результатов:\n",
      "Фильтрация может улучшить производительность за счет удаления лишних признаков.\n"
     ]
    }
   ],
   "source": [
    "# Обучение kNN\n",
    "knn_multi_filt = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_multi_filt.fit(X_train_multi_filt, y_train_multi)\n",
    "y_pred_multi_filt = knn_multi_filt.predict(X_test_multi_filt)\n",
    "\n",
    "# Метрики\n",
    "print(\"\\nМетрики с отобранными признаками (многоклассовая):\")\n",
    "print(f\"Точность (Accuracy): {accuracy_score(y_test_multi, y_pred_multi_filt):.4f}\")\n",
    "print(f\"Точность (Precision): {precision_score(y_test_multi, y_pred_multi_filt, average='weighted'):.4f}\")\n",
    "print(f\"Полнота (Recall): {recall_score(y_test_multi, y_pred_multi_filt, average='weighted'):.4f}\")\n",
    "print(f\"F1-мера: {f1_score(y_test_multi, y_pred_multi_filt, average='weighted'):.4f}\")\n",
    "print(\"\\nОтчет классификации:\")\n",
    "print(classification_report(y_test_multi, y_pred_multi_filt))\n",
    "\n",
    "# Сравнение\n",
    "print(\"\\nСравнение результатов:\")\n",
    "print(\"Фильтрация может улучшить производительность за счет удаления лишних признаков.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Кросс-валидация и лучший классификатор\n",
    "\n",
    "Проводим кросс-валидацию для выбора оптимального ( k ), обучаем лучший классификатор и строим матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Лучшее k для многоклассовой классификации: 18\n",
      "\n",
      "Метрики лучшего классификатора:\n",
      "Точность (Accuracy): 0.5467\n",
      "Точность (Precision): 0.5375\n",
      "Полнота (Recall): 0.5467\n",
      "F1-мера: 0.5380\n",
      "\n",
      "Отчет классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Long       0.36      0.43      0.39        86\n",
      "      Medium       0.41      0.31      0.35       110\n",
      "       Short       0.82      0.89      0.86       104\n",
      "\n",
      "    accuracy                           0.55       300\n",
      "   macro avg       0.53      0.54      0.53       300\n",
      "weighted avg       0.54      0.55      0.54       300\n",
      "\n",
      "\n",
      "Анализ матрицы ошибок:\n",
      "Диагональные элементы показывают правильные предсказания.\n",
      "Вне диагонали — ошибки, например, Short, предсказанный как Medium.\n"
     ]
    }
   ],
   "source": [
    "# Кросс-валидация\n",
    "train_scores_multi = []\n",
    "test_scores_multi = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn_cv_multi = KNeighborsClassifier(n_neighbors=k)\n",
    "    cv_scores = cross_val_score(knn_cv_multi, X_multi_filt_scaled, y_multi, cv=5, scoring='accuracy')\n",
    "    test_scores_multi.append(cv_scores.mean())\n",
    "    knn_cv_multi.fit(X_train_multi_filt, y_train_multi)\n",
    "    train_scores_multi.append(knn_cv_multi.score(X_train_multi_filt, y_train_multi))\n",
    "\n",
    "# График\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, train_scores_multi, label='Точность на обучении')\n",
    "plt.plot(k_values, test_scores_multi, label='Точность на тесте')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Точность')\n",
    "plt.title('Точность на обучении и тесте в зависимости от k (многоклассовая классификация)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('knn_accuracy_vs_k_multi.png')\n",
    "plt.close()\n",
    "\n",
    "# Лучший k\n",
    "best_k = k_values[np.argmax(test_scores_multi)]\n",
    "print(f\"\\nЛучшее k для многоклассовой классификации: {best_k}\")\n",
    "\n",
    "# Обучение лучшего классификатора\n",
    "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_best.fit(X_train_multi_filt, y_train_multi)\n",
    "y_pred_best = knn_best.predict(X_test_multi_filt)\n",
    "\n",
    "# Метрики\n",
    "print(\"\\nМетрики лучшего классификатора:\")\n",
    "print(f\"Точность (Accuracy): {accuracy_score(y_test_multi, y_pred_best):.4f}\")\n",
    "print(f\"Точность (Precision): {precision_score(y_test_multi, y_pred_best, average='weighted'):.4f}\")\n",
    "print(f\"Полнота (Recall): {recall_score(y_test_multi, y_pred_best, average='weighted'):.4f}\")\n",
    "print(f\"F1-мера: {f1_score(y_test_multi, y_pred_best, average='weighted'):.4f}\")\n",
    "print(\"\\nОтчет классификации:\")\n",
    "print(classification_report(y_test_multi, y_pred_best))\n",
    "\n",
    "# Матрица ошибок\n",
    "cm = confusion_matrix(y_test_multi, y_pred_best)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Short', 'Medium', 'Long'], yticklabels=['Short', 'Medium', 'Long'])\n",
    "plt.title('Матрица ошибок (лучший многоклассовый классификатор)')\n",
    "plt.xlabel('Предсказанный класс')\n",
    "plt.ylabel('Истинный класс')\n",
    "plt.savefig('confusion_matrix_multi.png')\n",
    "plt.close()\n",
    "\n",
    "# Анализ матрицы\n",
    "print(\"\\nАнализ матрицы ошибок:\")\n",
    "print(\"Диагональные элементы показывают правильные предсказания.\")\n",
    "print(\"Вне диагонали — ошибки, например, Short, предсказанный как Medium.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "- **Предобработка**: Пропуски в `margin_low` заполнены медианой.\n",
    "- **Нормализация**: Улучшает производительность kNN за счет стандартизации масштабов признаков.\n",
    "- **Отбор признаков**: Метод на основе корреляций (( T_{corr} = 0.3 ), ( T_{filter} = 0 )) позволяет выбрать наиболее информативные признаки.\n",
    "- **Бинарная классификация**: Высокая точность, особенно после нормализации и фильтрации.\n",
    "- **Многоклассовая классификация**: Искусственные классы на основе `length` дают умеренную точность; матрица ошибок показывает, какие классы путаются.\n",
    "- **Кросс-валидация**: Позволяет выбрать оптимальное ( k ), балансируя переобучение и недообучение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
